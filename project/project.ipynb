{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe62a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "\n",
    "W = 16      # timesteps per bar (16 = 16th notes)\n",
    "H = 128     # midi pitches\n",
    "\n",
    "def midi_to_bars(p: pretty_midi.PrettyMIDI, tempo=120, time_sig=(4,4)):\n",
    "    # Simplified: assume known bar boundaries by time signature & tempo\n",
    "    # Convert to piano-roll per bar at 16 steps per bar\n",
    "    # Return list of arrays shape (H, W) for melody channel\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739d81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# helper: conv block\n",
    "def conv_block(in_ch, out_ch, kernel, stride, padding, bn=True):\n",
    "    layers = [nn.Conv2d(in_ch, out_ch, kernel, stride, padding)]\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(out_ch))\n",
    "    layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# helper: deconv block\n",
    "def deconv_block(in_ch, out_ch, kernel, stride, padding, bn=True):\n",
    "    layers = [nn.ConvTranspose2d(in_ch, out_ch, kernel, stride, padding)]\n",
    "    if bn:\n",
    "        layers.append(nn.BatchNorm2d(out_ch))\n",
    "    layers.append(nn.ReLU(inplace=True))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ConditionerCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Takes a 2D piano-roll (H x W) and produces intermediate feature maps.\n",
    "    We'll build it so it outputs feature maps matching generator layers.\n",
    "    \"\"\"\n",
    "    def __init__(self, h=128, w=16, base_filters=64):\n",
    "        super().__init__()\n",
    "        # Input shape: (batch, 1, H, W)\n",
    "        # We'll compress vertical dimension progressively: convs chosen to match G transpose shapes.\n",
    "        self.conv1 = nn.Conv2d(1, base_filters, kernel_size=(128,1), stride=(1,1))  # -> (B, base, 1, W)\n",
    "        self.conv2 = nn.Conv2d(base_filters, base_filters, kernel_size=(1,2), stride=(1,2), padding=0)\n",
    "        self.conv3 = nn.Conv2d(base_filters, base_filters, kernel_size=(1,2), stride=(1,2))\n",
    "        self.conv4 = nn.Conv2d(base_filters, base_filters, kernel_size=(1,2), stride=(1,2))\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,1,H,W)\n",
    "        f1 = self.act(self.conv1(x))   # (B,base,1,W)\n",
    "        f2 = self.act(self.conv2(f1))  # (B,base,1,W/2)\n",
    "        f3 = self.act(self.conv3(f2))  # (B,base,1,W/4)\n",
    "        f4 = self.act(self.conv4(f3))  # (B,base,1,W/8) -> shapes to concat with G\n",
    "        return [f1, f2, f3, f4]\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, h=128, w=16, base_filters=128, cond1d_dim=None):\n",
    "        super().__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "        # fc layers\n",
    "        self.fc1 = nn.Linear(z_dim + (cond1d_dim or 0), 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        # reshape to (B, C, 1, 2) as in paper; choose C=base_filters\n",
    "        self.initial_C = base_filters\n",
    "        self.fc3 = nn.Linear(512, self.initial_C * 1 * 2)\n",
    "\n",
    "        # transposed conv stack (mirror conditioner convs)\n",
    "        # input maps shape: (B, initial_C, 1, 2)\n",
    "        self.deconv1 = deconv_block(self.initial_C, base_filters, kernel_size=(1,2), stride=(1,2), padding=0)\n",
    "        self.deconv2 = deconv_block(base_filters*2, base_filters, kernel_size=(1,2), stride=(1,2), padding=0) # after concat\n",
    "        self.deconv3 = deconv_block(base_filters*2, base_filters, kernel_size=(1,2), stride=(1,2), padding=0)\n",
    "        # last layer to expand to H x 16: kernel (H,1) with stride 1\n",
    "        self.deconv4 = nn.ConvTranspose2d(base_filters*2, 1, kernel_size=(h,1), stride=(1,1))\n",
    "\n",
    "        self.tanh = nn.Sigmoid()  # output in [0,1] for binary piano roll\n",
    "\n",
    "    def forward(self, z, cond2d_features=None, cond1d=None):\n",
    "        # z: (B, z_dim), cond2d_features: list of features from Conditioner CNN\n",
    "        if cond1d is not None:\n",
    "            z = torch.cat([z, cond1d], dim=1)\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        B = x.size(0)\n",
    "        x = x.view(B, self.initial_C, 1, 2)  # (B, C, 1, 2)\n",
    "\n",
    "        # deconv1: upsamples width -> size (B,base,1,4)\n",
    "        x = self.deconv1(x)\n",
    "        # concatenate cond feature at matching scale (if provided)\n",
    "        if cond2d_features is not None:\n",
    "            # cond2d_features[3] should match this spatial sizing; adjust ordering if necessary\n",
    "            c = cond2d_features[3]\n",
    "            x = torch.cat([x, c], dim=1)\n",
    "\n",
    "        x = self.deconv2(x)\n",
    "        if cond2d_features is not None:\n",
    "            c = cond2d_features[2]\n",
    "            x = torch.cat([x, c], dim=1)\n",
    "\n",
    "        x = self.deconv3(x)\n",
    "        if cond2d_features is not None:\n",
    "            c = cond2d_features[1]\n",
    "            x = torch.cat([x, c], dim=1)\n",
    "\n",
    "        # final projection to H x W\n",
    "        x = self.deconv4(x)  # -> (B,1,H,W)\n",
    "        x = self.tanh(x)     # [0,1] activations\n",
    "        # optionally force monophony per time-step by argmax along pitch dim in postprocessing\n",
    "        return x.squeeze(1)  # (B, H, W)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, h=128, w=16, base_filters=64, chord_dim=None):\n",
    "        super().__init__()\n",
    "        # Input: (B,1,H,W). If chord_dim provided, we'll embed and tile to spatial map or concat at fc stage.\n",
    "        self.conv1 = nn.Conv2d(1, 14, kernel_size=(h,2), stride=(1,2))  # as in paper first conv\n",
    "        self.conv2 = nn.Conv2d(14, 77, kernel_size=(1,4), stride=(1,2))\n",
    "        self.fc = nn.Linear(77 * 1 * 1 + (chord_dim or 0), 1024)  # shapes depend on conv outputs\n",
    "        self.out = nn.Linear(1024, 1)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, chord=None):\n",
    "        # x: (B,H,W) -> add channel\n",
    "        x = x.unsqueeze(1)\n",
    "        f = self.act(self.conv1(x))\n",
    "        f = self.act(self.conv2(f))\n",
    "        f = f.view(f.size(0), -1)\n",
    "        if chord is not None:\n",
    "            f = torch.cat([f, chord], dim=1)\n",
    "        f = self.act(self.fc(f))\n",
    "        return self.sig(self.out(f)).view(-1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
